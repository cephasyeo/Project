{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Project Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function that estimates the transition parameters from the training set using MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6480490669450607\n",
      "0.000787675624187137\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "we need 2 things:\n",
    "every tag pair for consecutive words\n",
    "every tag\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def estimate_emission_parameters(data):\n",
    "    count_y = defaultdict(int)\n",
    "    count_y_to_x = defaultdict(lambda: defaultdict(int))\n",
    "    for word, tag in data:\n",
    "        count_y[tag] += 1\n",
    "        count_y_to_x[tag][word] += 1\n",
    "\n",
    "    emission_probs = {}\n",
    "    for tag in count_y_to_x:\n",
    "        emission_probs[tag] = {}\n",
    "        for word in count_y_to_x[tag]:\n",
    "            emission_probs[tag][word] = count_y_to_x[tag][word] / count_y[tag]\n",
    "    return emission_probs\n",
    "\n",
    "def estimate_transition_parameters(sentences):\n",
    "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "    tag_counts = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        tags = [\"START\"] + sentence + [\"STOP\"]\n",
    "        for i in range(1, len(tags)):\n",
    "            prev_tag = tags[i - 1]\n",
    "            curr_tag = tags[i]\n",
    "            transition_counts[prev_tag][curr_tag] += 1\n",
    "            tag_counts[prev_tag] += 1\n",
    "\n",
    "    transition_probs = {}\n",
    "    for prev_tag in transition_counts:\n",
    "        transition_probs[prev_tag] = {}\n",
    "        for curr_tag in transition_counts[prev_tag]:\n",
    "            transition_probs[prev_tag][curr_tag] = transition_counts[prev_tag][curr_tag] / tag_counts[prev_tag]\n",
    "    return transition_probs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sentences = read_sentences(\"EN/train\")\n",
    "    transition_probs = estimate_transition_parameters(sentences)\n",
    "\n",
    "    # eg q(B-NP | START)\n",
    "    print(transition_probs[\"START\"].get(\"B-NP\", 0))\n",
    "\n",
    "    # eg q(STOP | I-NP)\n",
    "    print(transition_probs[\"I-NP\"].get(\"STOP\", 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Viterbi algorithm\n",
    "\n",
    "THIS IS WRONG AND INCOMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "given a sequence of words x1,...,xn, find the most likely tag sequence y1*,....,yn* using the Viterbi algo\n",
    "we need to maintain 2 things:\n",
    "pi[i][tag]: max log-prob of best path to position i ending in tag\n",
    "bp[i][tag]: best previous tag to reach tag at position i\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "SMALL_PROB = 1e-10\n",
    "\n",
    "def safe_log(p):\n",
    "    return math.log(p) if p > 0 else math.log(SMALL_PROB)\n",
    "\n",
    "def is_valid_transition(prev_tag, curr_tag):\n",
    "    if curr_tag == \"O\" or curr_tag.startswith(\"B-\"):\n",
    "        return True\n",
    "    if curr_tag.startswith(\"I-\"):\n",
    "        if prev_tag.startswith(\"B-\") or prev_tag.startswith(\"I-\"):\n",
    "            prev_type = prev_tag.split(\"-\")[1]\n",
    "            curr_type = curr_tag.split(\"-\")[1]\n",
    "            return prev_type == curr_type\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def viterbi(sentences, transition_probs, emission_probs, tag_set):\n",
    "    tagged_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        n = len(sentence)\n",
    "        V = [{} for _ in range(n)]\n",
    "        backpointer = [{} for _ in range(n)]\n",
    "\n",
    "        # Initialization\n",
    "        for tag in tag_set:\n",
    "            if tag in {\"START\", \"STOP\"}:\n",
    "                continue\n",
    "            emission = emission_probs[tag].get(sentence[0], emission_probs[tag].get(\"#UNK#\", SMALL_PROB))\n",
    "            trans = transition_probs.get(\"START\", {}).get(tag, SMALL_PROB)\n",
    "            V[0][tag] = safe_log(trans) + safe_log(emission)\n",
    "            backpointer[0][tag] = \"START\"\n",
    "\n",
    "        # Recursion\n",
    "        for t in range(1, n):\n",
    "            for curr_tag in tag_set:\n",
    "                if curr_tag in {\"START\", \"STOP\"}:\n",
    "                    continue\n",
    "                emission = emission_probs[curr_tag].get(sentence[t], emission_probs[curr_tag].get(\"#UNK#\", SMALL_PROB))\n",
    "                best_score = float('-inf')\n",
    "                best_prev_tag = None\n",
    "                for prev_tag in V[t - 1]:\n",
    "                    if not is_valid_transition(prev_tag, curr_tag):\n",
    "                        continue\n",
    "                    trans = transition_probs[prev_tag].get(curr_tag, SMALL_PROB)\n",
    "                    score = V[t - 1][prev_tag] + safe_log(trans) + safe_log(emission)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_prev_tag = prev_tag\n",
    "                if best_prev_tag is not None:\n",
    "                    V[t][curr_tag] = best_score\n",
    "                    backpointer[t][curr_tag] = best_prev_tag\n",
    "\n",
    "        # Termination\n",
    "        best_final_score = float('-inf')\n",
    "        best_last_tag = None\n",
    "        for tag in V[n - 1]:\n",
    "            trans = transition_probs[tag].get(\"STOP\", SMALL_PROB)\n",
    "            score = V[n - 1][tag] + safe_log(trans)\n",
    "            if score > best_final_score:\n",
    "                best_final_score = score\n",
    "                best_last_tag = tag\n",
    "\n",
    "        if best_last_tag is None:\n",
    "            best_last_tag = max(V[n - 1], key=V[n - 1].get, default=\"O\")\n",
    "\n",
    "        tags = [best_last_tag]\n",
    "        for t in range(n - 1, 0, -1):\n",
    "            tags.insert(0, backpointer[t].get(tags[0], \"O\"))\n",
    "\n",
    "        tagged_sentences.append(list(zip(sentence, tags)))\n",
    "\n",
    "    return tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS IS THE FUNCTIONS FROM PART 1\n",
    "\n",
    "def read_training_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                word, tag = line.strip().split()\n",
    "                data.append((word, tag))\n",
    "    return data\n",
    "\n",
    "def count_word_frequencies(data):\n",
    "    word_counts = defaultdict(int)\n",
    "    for word, _ in data:\n",
    "        word_counts[word] += 1\n",
    "    return word_counts\n",
    "\n",
    "def replace_rare_words(data, word_counts, k=3):\n",
    "    new_data = []\n",
    "    for word, tag in data:\n",
    "        if word_counts[word] < k:\n",
    "            new_data.append(('#UNK#', tag))\n",
    "        else:\n",
    "            new_data.append((word, tag))\n",
    "    return new_data\n",
    "\n",
    "def read_sentences(file_path):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                _, tag = line.split()\n",
    "                sentence.append(tag)\n",
    "            else:\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def read_dev_sentences(dev_path, word_counts, k=3):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    with open(dev_path, 'r') as f:\n",
    "        for line in f:\n",
    "            word = line.strip()\n",
    "            if word:\n",
    "                if word_counts[word] < k:\n",
    "                    sentence.append(\"#UNK#\")\n",
    "                else:\n",
    "                    sentence.append(word)\n",
    "            else:\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare training data\n",
    "    train_data = read_training_data(\"EN/train\")\n",
    "    word_counts = count_word_frequencies(train_data)\n",
    "    train_data_unk = replace_rare_words(train_data, word_counts, k=3)\n",
    "    emission_probs = estimate_emission_parameters(train_data_unk)\n",
    "\n",
    "    # Estimate transition parameters\n",
    "    tag_only_sentences = read_sentences(\"EN/train\")\n",
    "    transition_probs = estimate_transition_parameters(tag_only_sentences)\n",
    "\n",
    "    # Build filtered tag set\n",
    "    tag_freqs = Counter(tag for _, tag in train_data)\n",
    "    tag_set = {tag for tag, count in tag_freqs.items() if count >= 20} | {\"START\", \"STOP\"}\n",
    "\n",
    "    # Ensure all tags have #UNK# entries\n",
    "    for tag in tag_set:\n",
    "        if tag not in emission_probs:\n",
    "            emission_probs[tag] = {}\n",
    "        if \"#UNK#\" not in emission_probs[tag]:\n",
    "            emission_probs[tag][\"#UNK#\"] = SMALL_PROB\n",
    "\n",
    "    # Read dev input and run Viterbi\n",
    "    dev_sentences = read_dev_sentences(\"EN/dev.in\", word_counts, k=3)\n",
    "    tagged_sentences = viterbi(dev_sentences, transition_probs, emission_probs, tag_set)\n",
    "\n",
    "    # Write output\n",
    "    with open(\"EN/dev.p2.out\", \"w\") as f:\n",
    "        for sentence in tagged_sentences:\n",
    "            for word, tag in sentence:\n",
    "                f.write(f\"{word} {tag}\\n\")\n",
    "            f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
