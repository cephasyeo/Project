{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project Part 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function that estimates the emission parameters from the training set using MLE (maximum likelihood estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(filename):\n",
    "    \"\"\"Reads training data and returns a list of (word, tag) pairs.\"\"\"\n",
    "    data = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            word, tag = line.split()\n",
    "            data.append((word, tag))\n",
    "    return data\n",
    "\n",
    "def estimate_emission_parameters(data):\n",
    "    \"\"\"Estimates emission probabilities e(x|y) using MLE.\"\"\"\n",
    "    from collections import defaultdict\n",
    "\n",
    "    # Count(y) - how many times a tag y appeared\n",
    "    tag_counts = defaultdict(int)\n",
    "\n",
    "    # Count(y -> x) - how many times a word x appeared with tag y\n",
    "    emission_counts = defaultdict(int)\n",
    "\n",
    "    for word, tag in data:\n",
    "        tag_counts[tag] += 1\n",
    "        emission_counts[(tag, word)] += 1\n",
    "\n",
    "    # Compute emission probabilities\n",
    "    emission_probs = {}\n",
    "    for (tag, word), count in emission_counts.items():\n",
    "        emission_probs[(tag, word)] = count / tag_counts[tag]\n",
    "\n",
    "    return emission_probs, tag_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Unknown Words with Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_rare_words(data, k=3):\n",
    "    \"\"\"Replace words appearing less than k times with #UNK#.\"\"\"\n",
    "    from collections import Counter\n",
    "\n",
    "    word_counter = Counter([word for word, tag in data])\n",
    "    updated_data = []\n",
    "\n",
    "    for word, tag in data:\n",
    "        if word_counter[word] < k:\n",
    "            updated_data.append((\"#UNK#\", tag))\n",
    "        else:\n",
    "            updated_data.append((word, tag))\n",
    "\n",
    "    return updated_data\n",
    "\n",
    "def estimate_emission_parameters_with_smoothing(filename, k=3):\n",
    "    \"\"\"Reads training data, replaces rare words, and estimates emission probabilities.\"\"\"\n",
    "    data = read_training_data(filename)\n",
    "    data = replace_rare_words(data, k)\n",
    "    emission_probs, tag_counts = estimate_emission_parameters(data)\n",
    "    return emission_probs, tag_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dev_data(filename):\n",
    "    \"\"\"Reads the dev.in file and returns a list of sentences (each sentence is a list of words).\"\"\"\n",
    "    sentences = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        sentence = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            else:\n",
    "                sentence.append(line)\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def simple_tagging(emission_probs, tag_counts, dev_filename, output_filename):\n",
    "    \"\"\"Tags each word individually with the highest emission probability.\"\"\"\n",
    "    sentences = read_dev_data(dev_filename)\n",
    "\n",
    "    all_tags = list(tag_counts.keys())\n",
    "\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                best_tag = None\n",
    "                best_score = 0\n",
    "                for tag in all_tags:\n",
    "                    if (tag, word) in emission_probs:\n",
    "                        score = emission_probs[(tag, word)]\n",
    "                    elif (tag, \"#UNK#\") in emission_probs:\n",
    "                        score = emission_probs[(tag, \"#UNK#\")]\n",
    "                    else:\n",
    "                        score = 0\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_tag = tag\n",
    "                f.write(f\"{word} {best_tag}\\n\")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "After running \"py EvalScript/evalResult.py EN/dev.out EN/dev.p1.out\":\n",
    "\n",
    "#Entity in gold data: 13179<br>\n",
    "#Entity in prediction: 17085\n",
    "\n",
    "#Correct Entity : 9186<br>\n",
    "Entity  precision: 0.5377<br>\n",
    "Entity  recall: 0.6970<br>\n",
    "Entity  F: 0.6071\n",
    "\n",
    "#Correct Sentiment : 8261<br>\n",
    "Sentiment  precision: 0.4835<br>\n",
    "Sentiment  recall: 0.6268<br>\n",
    "Sentiment  F: 0.5459"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function that estimates the transition parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_sentences(filename):\n",
    "    \"\"\"Reads training file and returns list of sentences, each sentence is a list of (word, tag) pairs.\"\"\"\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            else:\n",
    "                word, tag = line.split()\n",
    "                sentence.append((word, tag))\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def estimate_transition_parameters(sentences):\n",
    "    \"\"\"Estimates transition probabilities q(y_i|y_{i-1}) using MLE.\"\"\"\n",
    "    from collections import defaultdict\n",
    "\n",
    "    bigram_counts = defaultdict(int)\n",
    "    unigram_counts = defaultdict(int)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tags = [tag for word, tag in sentence]\n",
    "        tags = [\"START\"] + tags + [\"STOP\"]\n",
    "\n",
    "        for i in range(len(tags) - 1):\n",
    "            unigram_counts[tags[i]] += 1\n",
    "            bigram_counts[(tags[i], tags[i+1])] += 1\n",
    "\n",
    "    transition_probs = {}\n",
    "    for (tag_prev, tag_curr), count in bigram_counts.items():\n",
    "        transition_probs[(tag_prev, tag_curr)] = count / unigram_counts[tag_prev]\n",
    "\n",
    "    return transition_probs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def safe_log(x):\n",
    "    \"\"\"Safe log: returns log(x) if x > 0, else -inf.\"\"\"\n",
    "    return math.log(x) if x > 0 else float('-inf')\n",
    "\n",
    "def read_dev_sentences(dev_path):\n",
    "    \"\"\"Reads sentences from dev.in into a list of sentences.\"\"\"\n",
    "    sentences = []\n",
    "    with open(dev_path, 'r') as f:\n",
    "        sentence = []\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                sentence.append(line.strip())\n",
    "            else:\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def viterbi(dev_path, output_path, emission_probs, transition_probs, tag_set, known_words):\n",
    "    \"\"\"Viterbi decoding algorithm.\"\"\"\n",
    "    sentences = read_dev_sentences(dev_path)\n",
    "\n",
    "    with open(output_path, 'w') as out:\n",
    "        for sentence in sentences:\n",
    "            n = len(sentence)\n",
    "            V = defaultdict(lambda: defaultdict(lambda: -math.inf))\n",
    "            backpointer = defaultdict(dict)\n",
    "\n",
    "            V[0]['START'] = 0\n",
    "\n",
    "            for i in range(1, n+1):\n",
    "                word = sentence[i-1]\n",
    "                word_key = word if word in known_words else '#UNK#'\n",
    "                for curr_tag in tag_set:\n",
    "                    emit = emission_probs[curr_tag].get(word_key, 0)\n",
    "                    if emit == 0:\n",
    "                        continue\n",
    "                    for prev_tag in V[i-1]:\n",
    "                        trans = transition_probs.get((prev_tag, curr_tag), 0)\n",
    "                        if trans == 0:\n",
    "                            continue\n",
    "                        score = V[i-1][prev_tag] + safe_log(trans) + safe_log(emit)\n",
    "                        if score > V[i][curr_tag]:\n",
    "                            V[i][curr_tag] = score\n",
    "                            backpointer[i][curr_tag] = prev_tag\n",
    "\n",
    "            # Termination\n",
    "            best_score = -math.inf\n",
    "            best_last_tag = None\n",
    "            for tag in V[n]:\n",
    "                trans = transition_probs.get((tag, 'STOP'), 0)\n",
    "                if trans == 0:\n",
    "                    continue\n",
    "                score = V[n][tag] + safe_log(trans)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_last_tag = tag\n",
    "\n",
    "            # Backtrack\n",
    "            if best_last_tag is None:\n",
    "                best_path = ['O'] * n\n",
    "            else:\n",
    "                best_path = [best_last_tag]\n",
    "                for i in range(n, 1, -1):\n",
    "                    best_path.insert(0, backpointer[i][best_path[0]])\n",
    "\n",
    "            # Write output\n",
    "            for word, tag in zip(sentence, best_path):\n",
    "                out.write(f\"{word} {tag}\\n\")\n",
    "            out.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Part 2's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_training_data('EN/train')\n",
    "data = replace_rare_words(data, k=3)\n",
    "emission_probs_raw, tag_counts = estimate_emission_parameters(data)\n",
    "\n",
    "# Organize emission_probs into emission_probs[tag][word]\n",
    "from collections import defaultdict\n",
    "emission_probs = defaultdict(dict)\n",
    "for (tag, word), prob in emission_probs_raw.items():\n",
    "    emission_probs[tag][word] = prob\n",
    "\n",
    "sentences = read_training_sentences('EN/train')\n",
    "transition_probs = estimate_transition_parameters(sentences)\n",
    "known_words = set(word for (word, tag) in data)\n",
    "tag_set = set(tag_counts.keys())\n",
    "viterbi('EN/dev.in', 'EN/dev.p2.out', emission_probs, transition_probs, tag_set, known_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "After running \"py EvalScript/evalResult.py EN/dev.out EN/dev.p2.out\":\n",
    "\n",
    "#Entity in gold data: 13179<br>\n",
    "#Entity in prediction: 12492\n",
    "\n",
    "#Correct Entity : 10627<br>\n",
    "Entity  precision: 0.8507<br>\n",
    "Entity  recall: 0.8064<br>\n",
    "Entity  F: 0.8279\n",
    "\n",
    "#Correct Sentiment : 10224<br>\n",
    "Sentiment  precision: 0.8184<br>\n",
    "Sentiment  recall: 0.7758<br>\n",
    "Sentiment  F: 0.7965"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project Part 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for 4th Best Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def safe_log(x):\n",
    "    \"\"\"Safe log: returns log(x) if x > 0, else -inf.\"\"\"\n",
    "    return math.log(x) if x > 0 else float('-inf')\n",
    "\n",
    "def read_dev_sentences(dev_path):\n",
    "    \"\"\"Reads sentences from dev.in into a list of sentences.\"\"\"\n",
    "    sentences = []\n",
    "    with open(dev_path, 'r') as f:\n",
    "        sentence = []\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                sentence.append(line.strip())\n",
    "            else:\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def viterbi_4th_best(dev_path, output_path, emission_probs, transition_probs, tag_set, known_words):\n",
    "    \"\"\"Viterbi decoding that finds the 4th best sequence.\"\"\"\n",
    "    sentences = read_dev_sentences(dev_path)\n",
    "\n",
    "    with open(output_path, 'w') as out:\n",
    "        for sentence in sentences:\n",
    "            n = len(sentence)\n",
    "\n",
    "            # dp[i][tag] = list of (score, previous_tag, rank) tuples, top 4 at each step\n",
    "            dp = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "            dp[0]['START'].append((0, None, 1))  # (log-prob, previous tag, rank)\n",
    "\n",
    "            for i in range(1, n+1):\n",
    "                word = sentence[i-1]\n",
    "                word_key = word if word in known_words else '#UNK#'\n",
    "\n",
    "                for curr_tag in tag_set:\n",
    "                    emit_prob = emission_probs[curr_tag].get(word_key, 0)\n",
    "                    if emit_prob == 0:\n",
    "                        continue\n",
    "                    log_emit = safe_log(emit_prob)\n",
    "\n",
    "                    candidates = []\n",
    "                    for prev_tag in dp[i-1]:\n",
    "                        trans_prob = transition_probs.get((prev_tag, curr_tag), 0)\n",
    "                        if trans_prob == 0:\n",
    "                            continue\n",
    "                        log_trans = safe_log(trans_prob)\n",
    "\n",
    "                        for (prev_score, _, _) in dp[i-1][prev_tag]:\n",
    "                            score = prev_score + log_trans + log_emit\n",
    "                            candidates.append((score, prev_tag))\n",
    "\n",
    "                    # Sort candidates and pick top-4\n",
    "                    candidates = sorted(candidates, key=lambda x: x[0], reverse=True)[:4]\n",
    "                    for rank, (score, prev_tag) in enumerate(candidates, start=1):\n",
    "                        dp[i][curr_tag].append((score, prev_tag, rank))\n",
    "\n",
    "            # Termination: go from last word to STOP\n",
    "            final_candidates = []\n",
    "            for tag in dp[n]:\n",
    "                trans_prob = transition_probs.get((tag, 'STOP'), 0)\n",
    "                if trans_prob == 0:\n",
    "                    continue\n",
    "                log_trans = safe_log(trans_prob)\n",
    "\n",
    "                for (score, _, _) in dp[n][tag]:\n",
    "                    final_score = score + log_trans\n",
    "                    final_candidates.append((final_score, tag))\n",
    "\n",
    "            if not final_candidates:\n",
    "                # fallback: tag everything as 'O'\n",
    "                best_path = ['O'] * n\n",
    "            else:\n",
    "                # Sort final candidates and pick the 4th-best\n",
    "                final_candidates = sorted(final_candidates, key=lambda x: x[0], reverse=True)\n",
    "                \n",
    "                if len(final_candidates) < 4:\n",
    "                    target_index = len(final_candidates) - 1\n",
    "                else:\n",
    "                    target_index = 3  # 0-based index, so 3 means 4th-best\n",
    "\n",
    "                best_last_tag = final_candidates[target_index][1]\n",
    "\n",
    "                # Backtrack\n",
    "                best_path = []\n",
    "                current_tag = best_last_tag\n",
    "                for i in range(n, 0, -1):\n",
    "                    candidates = dp[i][current_tag]\n",
    "                    # Pick the best-ranked candidate\n",
    "                    candidates_sorted = sorted(candidates, key=lambda x: x[0], reverse=True)\n",
    "                    best_prev_tag = candidates_sorted[0][1]\n",
    "                    best_path.append(current_tag)\n",
    "                    current_tag = best_prev_tag\n",
    "                best_path.reverse()\n",
    "\n",
    "            # Write output\n",
    "            for word, tag in zip(sentence, best_path):\n",
    "                out.write(f\"{word} {tag}\\n\")\n",
    "            out.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Part 3's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_training_data('EN/train')\n",
    "data = replace_rare_words(data, k=3)\n",
    "emission_probs_raw, tag_counts = estimate_emission_parameters(data)\n",
    "\n",
    "from collections import defaultdict\n",
    "emission_probs = defaultdict(dict)\n",
    "for (tag, word), prob in emission_probs_raw.items():\n",
    "    emission_probs[tag][word] = prob\n",
    "\n",
    "sentences = read_training_sentences('EN/train')\n",
    "transition_probs = estimate_transition_parameters(sentences)\n",
    "\n",
    "known_words = set(word for (word, tag) in data)\n",
    "tag_set = set(tag_counts.keys())\n",
    "viterbi_4th_best('EN/dev.in', 'EN/dev.p3.out', emission_probs, transition_probs, tag_set, known_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "After running \"py EvalScript/evalResult.py EN/dev.out EN/dev.p3.out\":\n",
    "\n",
    "#Entity in gold data: 13179<br>\n",
    "#Entity in prediction: 12494\n",
    "\n",
    "#Correct Entity : 10617<br>\n",
    "Entity  precision: 0.8498<br>\n",
    "Entity  recall: 0.8056<br>\n",
    "Entity  F: 0.8271\n",
    "\n",
    "#Correct Sentiment : 10212<br>\n",
    "Sentiment  precision: 0.8174<br>\n",
    "Sentiment  recall: 0.7749<br>\n",
    "Sentiment  F: 0.7955"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project Part 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(word, prev_tag):\n",
    "    \"\"\"Extract features for a given word and previous tag.\"\"\"\n",
    "    features = {}\n",
    "    features['bias'] = 1\n",
    "    features['word.lower=' + word.lower()] = 1\n",
    "    features['prev_tag=' + prev_tag] = 1\n",
    "    if word[0].isupper():\n",
    "        features['is_capitalized'] = 1\n",
    "    if word.isdigit():\n",
    "        features['is_digit'] = 1\n",
    "    return features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def train_perceptron(train_data, tag_set, num_epochs=20):\n",
    "    \"\"\"Train Perceptron sequence tagger.\"\"\"\n",
    "    weights = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for word, tag in train_data:\n",
    "        if word == \"\" and tag == \"\":\n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "        else:\n",
    "            sentence.append((word, tag))\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        random.shuffle(sentences)\n",
    "        for sentence in sentences:\n",
    "            words, gold_tags = zip(*sentence)\n",
    "            n = len(words)\n",
    "\n",
    "            # Predict tags\n",
    "            pred_tags = []\n",
    "            prev_tag = 'START'\n",
    "            for word in words:\n",
    "                scores = {}\n",
    "                for tag in tag_set:\n",
    "                    score = 0\n",
    "                    feats = extract_features(word, prev_tag)\n",
    "                    for f, value in feats.items():\n",
    "                        score += weights[f][tag] * value\n",
    "                    scores[tag] = score\n",
    "                best_tag = max(scores, key=scores.get)\n",
    "                pred_tags.append(best_tag)\n",
    "                prev_tag = best_tag\n",
    "\n",
    "            # Update weights\n",
    "            prev_tag = 'START'\n",
    "            for i in range(n):\n",
    "                word = words[i]\n",
    "                true_tag = gold_tags[i]\n",
    "                pred_tag = pred_tags[i]\n",
    "                if true_tag != pred_tag:\n",
    "                    true_feats = extract_features(word, prev_tag)\n",
    "                    pred_feats = extract_features(word, prev_tag)\n",
    "                    for f, value in true_feats.items():\n",
    "                        weights[f][true_tag] += value\n",
    "                        weights[f][pred_tag] -= value\n",
    "                prev_tag = pred_tag\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(sentence, weights, tag_set):\n",
    "    \"\"\"Tag a sentence using learned perceptron weights.\"\"\"\n",
    "    pred_tags = []\n",
    "    prev_tag = 'START'\n",
    "    for word in sentence:\n",
    "        scores = {}\n",
    "        for tag in tag_set:\n",
    "            score = 0\n",
    "            feats = extract_features(word, prev_tag)\n",
    "            for f, value in feats.items():\n",
    "                score += weights[f][tag] * value\n",
    "            scores[tag] = score\n",
    "        best_tag = max(scores, key=scores.get)\n",
    "        pred_tags.append(best_tag)\n",
    "        prev_tag = best_tag\n",
    "    return pred_tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function to Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_main(train_file, dev_in_file, dev_out_file):\n",
    "    \"\"\"Train and run Perceptron model.\"\"\"\n",
    "    # Read training data\n",
    "    train_data = []\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                word, tag = line.split()\n",
    "                train_data.append((word, tag))\n",
    "            else:\n",
    "                train_data.append((\"\", \"\"))\n",
    "\n",
    "    tag_set = set(tag for word, tag in train_data if tag)\n",
    "\n",
    "    # Train\n",
    "    weights = train_perceptron(train_data, tag_set, num_epochs=20)\n",
    "\n",
    "    # Read dev.in\n",
    "    sentences = read_dev_sentences(dev_in_file)\n",
    "\n",
    "    # Predict and write output\n",
    "    with open(dev_out_file, 'w', encoding='utf-8') as out:\n",
    "        for sentence in sentences:\n",
    "            pred_tags = tag_sentence(sentence, weights, tag_set)\n",
    "            for word, tag in zip(sentence, pred_tags):\n",
    "                out.write(f\"{word} {tag}\\n\")\n",
    "            out.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Part 4's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_main('EN/train', 'EN/dev.in', 'EN/dev.p4.out')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "After running \"py EvalScript/evalResult.py EN/dev.out EN/dev.p4.out\":\n",
    "\n",
    "#Entity in gold data: 13179<br>\n",
    "#Entity in prediction: 12494\n",
    "\n",
    "#Correct Entity : 10617<br>\n",
    "Entity  precision: 0.8498<br>\n",
    "Entity  recall: 0.8056<br>\n",
    "Entity  F: 0.8271\n",
    "\n",
    "#Correct Sentiment : 10212<br>\n",
    "Sentiment  precision: 0.8174<br>\n",
    "Sentiment  recall: 0.7749<br>\n",
    "Sentiment  F: 0.7955"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
